{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Jh2Ga2KSvp",
        "outputId": "c1dd8f4d-1cc1-483a-d8cb-b5e404618b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/2\n",
            "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5255 - loss: 0.6926 - val_accuracy: 0.6888 - val_loss: 0.6872\n",
            "Epoch 2/2\n",
            "\u001b[1m40/40\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6563 - loss: 0.6840 - val_accuracy: 0.6822 - val_loss: 0.6669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a movie review: The plot was amazing and the acting was superb!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "Prediction: Hit ğŸ¬\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "\n",
        "# Load IMDb dataset word index (to simulate tokenizer)\n",
        "word_index = imdb.get_word_index()\n",
        "index_word = {v+3: k for k, v in word_index.items()}\n",
        "word_index = {k: (v+3) for k, v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# Load pretrained model (or build one if needed)\n",
        "# For demo, we'll build a quick one below. You can skip this block if you have a model already.\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "x_train = pad_sequences(x_train, maxlen=256, padding='post')\n",
        "x_test = pad_sequences(x_test, maxlen=256, padding='post')\n",
        "\n",
        "# Build and train a simple model (train once and save)\n",
        "model = Sequential([\n",
        "    Embedding(10000, 16),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=2, batch_size=512, validation_split=0.2)\n",
        "model.save(\"movie_review_model.h5\")\n",
        "\n",
        "# Load model (use this part once saved)\n",
        "model = load_model(\"movie_review_model.h5\")\n",
        "\n",
        "# Function to convert review text to sequence\n",
        "def review_to_sequence(text):\n",
        "    tokens = text.lower().split()\n",
        "    seq = [word_index.get(word, 2) for word in tokens]\n",
        "    return pad_sequences([seq], maxlen=256, padding='post')\n",
        "\n",
        "# Prediction function\n",
        "def predict_review(text):\n",
        "    sequence = review_to_sequence(text)\n",
        "    prediction = model.predict(sequence)[0][0]\n",
        "    return \"Hit ğŸ¬\" if prediction > 0.5 else \"Flop ğŸ’£\"\n",
        "\n",
        "# Main\n",
        "if __name__ == \"__main__\":\n",
        "    review = input(\"Enter a movie review: \")\n",
        "    result = predict_review(review)\n",
        "    print(\"Prediction:\", result)"
      ]
    }
  ]
}